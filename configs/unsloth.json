{
  "name": "unsloth",
  "description": "Unsloth is a library for 2-5x faster LLM fine-tuning with 70-80% less VRAM. Use this skill when: fine-tuning language models (Llama 3, Mistral, Gemma 2, Qwen 2.5, DeepSeek, Phi-4), using LoRA/QLoRA/full fine-tuning, handling long context up to 500K tokens, multi-GPU distributed training, vision model fine-tuning (LLaVA, Pixtral), reinforcement learning (GRPO, DPO, PPO, ORPO), continued pretraining, or exporting to GGUF/vLLM/Ollama formats.",
  "base_url": "https://docs.unsloth.ai/",
  "start_urls": [
    "https://docs.unsloth.ai/",
    "https://docs.unsloth.ai/get-started/beginner-start-here",
    "https://docs.unsloth.ai/get-started/fine-tuning-for-beginners",
    "https://docs.unsloth.ai/get-started/installation",
    "https://docs.unsloth.ai/get-started/unsloth-notebook-catalog",
    "https://docs.unsloth.ai/get-started/which-model-to-use",
    "https://docs.unsloth.ai/basics/inference",
    "https://docs.unsloth.ai/basics/finetuning-from-a-custom-dataset",
    "https://docs.unsloth.ai/basics/chat-templates",
    "https://docs.unsloth.ai/basics/data-preparation",
    "https://docs.unsloth.ai/basics/multi-gpu-training",
    "https://docs.unsloth.ai/basics/vision-finetuning",
    "https://docs.unsloth.ai/basics/continued-pretraining",
    "https://docs.unsloth.ai/basics/reward-modelling",
    "https://docs.unsloth.ai/basics/exporting-to-gguf",
    "https://docs.unsloth.ai/basics/exporting-to-vllm",
    "https://docs.unsloth.ai/basics/exporting-to-ollama",
    "https://docs.unsloth.ai/basics/merging-lora",
    "https://docs.unsloth.ai/tutorials/how-to-finetune-llama-3-and-deploy-locally",
    "https://docs.unsloth.ai/tutorials/how-to-finetune-mistral-22b",
    "https://docs.unsloth.ai/tutorials/how-to-finetune-gemma",
    "https://docs.unsloth.ai/tutorials/how-to-finetune-qwen",
    "https://docs.unsloth.ai/tutorials/how-to-finetune-deepseek",
    "https://docs.unsloth.ai/tutorials/how-to-finetune-phi",
    "https://docs.unsloth.ai/tutorials/grpo-reinforcement-learning",
    "https://docs.unsloth.ai/tutorials/dpo-training",
    "https://docs.unsloth.ai/tutorials/orpo-training",
    "https://docs.unsloth.ai/new-features/3x-longer-context-finetuning",
    "https://docs.unsloth.ai/new-features/500k-context-support",
    "https://docs.unsloth.ai/new-features/fp8-rl-training",
    "https://docs.unsloth.ai/new-features/dynamic-4bit-quantization",
    "https://docs.unsloth.ai/new-features/triton-kernels",
    "https://docs.unsloth.ai/troubleshooting/common-errors",
    "https://docs.unsloth.ai/troubleshooting/faqs",
    "https://docs.unsloth.ai/troubleshooting/memory-issues"
  ],
  "selectors": {
    "main_content": "article, main, [class*='content'], [class*='prose']",
    "title": "title",
    "code_blocks": "pre, code, [class*='code']"
  },
  "url_patterns": {
    "include": [
      "/get-started/",
      "/basics/",
      "/tutorials/",
      "/new-features/",
      "/troubleshooting/",
      "/models/",
      "/advanced/"
    ],
    "exclude": [
      "/search",
      "/_next/",
      "/static/",
      ".css",
      ".js",
      ".json",
      ".xml",
      "/api/",
      "github.com",
      "discord.com",
      "reddit.com",
      "twitter.com",
      "huggingface.co"
    ]
  },
  "categories": {
    "getting_started": ["get-started", "beginner", "installation", "install", "quickstart", "introduction", "catalog", "which-model"],
    "fine_tuning": ["finetune", "fine-tuning", "finetuning", "training", "train", "lora", "qlora", "sft", "supervised"],
    "models": ["llama", "mistral", "gemma", "qwen", "deepseek", "phi", "codellama", "model", "tinyllama", "yi"],
    "reinforcement_learning": ["grpo", "dpo", "ppo", "orpo", "rlhf", "reinforcement", "reward", "preference"],
    "inference": ["inference", "generate", "prediction", "run", "deploy", "serve"],
    "vision": ["vision", "multimodal", "image", "llava", "pixtral", "visual"],
    "long_context": ["context", "500k", "long-context", "rope", "scaling", "3x-longer"],
    "multi_gpu": ["multi-gpu", "distributed", "fsdp", "ddp", "deepspeed", "parallel"],
    "export": ["export", "gguf", "vllm", "ollama", "format", "save", "merge", "merging"],
    "optimization": ["optimization", "memory", "speed", "fp8", "quantization", "faster", "triton", "dynamic-4bit"],
    "datasets": ["dataset", "data", "custom", "alpaca", "sharegpt", "chat", "template", "preparation"],
    "pretraining": ["pretraining", "continued", "pretrain", "from-scratch"],
    "troubleshooting": ["troubleshooting", "error", "faq", "common", "issue", "problem", "memory-issues"]
  },
  "rate_limit": 0.5,
  "max_pages": 250
}
